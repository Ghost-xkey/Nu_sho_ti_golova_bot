# üé§ –ü—Ä–æ—Å—Ç–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

## üìã **–ß—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ:**

### **1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª speech_kit.py:**
```bash
nano speech_kit.py
```

### **2. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –≤—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥:**
```python
import requests
import json
import logging
import io
import base64
from config import (
    YANDEX_API_KEY, YANDEX_FOLDER_ID, 
    VOICE_ENABLED, VOICE_LANGUAGE, VOICE_GENDER, 
    VOICE_EMOTION, VOICE_SPEED, VOICE_FORMAT
)

class YandexSpeechKit:
    def __init__(self):
        self.api_key = YANDEX_API_KEY
        self.folder_id = YANDEX_FOLDER_ID
        self.stt_url = "https://stt.api.cloud.yandex.net/speech/v1/stt:recognize"
        self.tts_url = "https://tts.api.cloud.yandex.net/speech/v1/tts:synthesize"
        
    def get_headers(self):
        return {
            "Authorization": f"Api-Key {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def voice_to_text(self, voice_data: bytes) -> str:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–µ–∫—Å—Ç
        """
        try:
            if not VOICE_ENABLED:
                logging.warning("Voice processing is disabled")
                return ""
                
            # –ö–æ–¥–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ base64
            audio_base64 = base64.b64encode(voice_data).decode('utf-8')
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è API
            data = {
                "config": {
                    "specification": {
                        "languageCode": VOICE_LANGUAGE,
                        "model": "general",
                        "profanityFilter": False,
                        "audioEncoding": "OGG_OPUS",
                        "sampleRateHertz": 48000
                    }
                },
                "audio": {
                    "content": audio_base64
                }
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Speech-to-Text API
            response = requests.post(
                self.stt_url,
                headers=self.get_headers(),
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                if "result" in result and "alternatives" in result["result"]:
                    text = result["result"]["alternatives"][0]["text"]
                    logging.info(f"Voice-to-text successful: {text[:50]}...")
                    return text
                else:
                    logging.warning("No text found in voice recognition result")
                    return ""
            else:
                logging.error(f"Speech-to-Text API error: {response.status_code} - {response.text}")
                return ""
                
        except Exception as e:
            logging.error(f"Error converting voice to text: {e}")
            return ""
    
    def text_to_voice(self, text: str) -> bytes:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        try:
            if not VOICE_ENABLED:
                logging.warning("Voice processing is disabled")
                return b""
                
            # –í—ã–±–∏—Ä–∞–µ–º –≥–æ–ª–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫
            voice_name = "filipp" if VOICE_GENDER == "male" else "jane"
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è API
            data = {
                "text": text,
                "lang": VOICE_LANGUAGE,
                "voice": voice_name,
                "emotion": "evil",  # –ì—Ä—É–±–∞—è —ç–º–æ—Ü–∏—è
                "speed": VOICE_SPEED,
                "format": VOICE_FORMAT
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Text-to-Speech API
            response = requests.post(
                self.tts_url,
                headers=self.get_headers(),
                data=data,
                timeout=10
            )
            
            if response.status_code == 200:
                audio_data = response.content
                logging.info(f"Text-to-voice successful for: {text[:50]}...")
                return audio_data
            else:
                logging.error(f"Text-to-Speech API error: {response.status_code} - {response.text}")
                return b""
                
        except Exception as e:
            logging.error(f"Error converting text to voice: {e}")
            return b""

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä SpeechKit
speech_kit = YandexSpeechKit()

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def voice_to_text(voice_data: bytes) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≥–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç"""
    return speech_kit.voice_to_text(voice_data)

def text_to_voice(text: str) -> bytes:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ –≥–æ–ª–æ—Å"""
    return speech_kit.text_to_voice(text)
```

### **3. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ñ–∞–π–ª:**
- –ù–∞–∂–º–∏—Ç–µ `Ctrl + X`
- –ù–∞–∂–º–∏—Ç–µ `Y`
- –ù–∞–∂–º–∏—Ç–µ `Enter`

### **4. –û–±–Ω–æ–≤–∏—Ç–µ config.py:**
```bash
nano config.py
```

### **5. –î–æ–±–∞–≤—å—Ç–µ –≤ –∫–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞:**
```python
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
VOICE_ENABLED = True  # –í–∫–ª—é—á–µ–Ω—ã –ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
VOICE_LANGUAGE = "ru-RU"  # –Ø–∑—ã–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
VOICE_GENDER = "male"  # –ü–æ–ª –≥–æ–ª–æ—Å–∞ (male/female)
VOICE_EMOTION = "evil"  # –≠–º–æ—Ü–∏—è –≥–æ–ª–æ—Å–∞ (neutral, good, evil, mixed)
VOICE_SPEED = "1.0"  # –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ (0.1-3.0)
VOICE_FORMAT = "oggopus"  # –§–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ (oggopus, mp3, wav, lpcm)
```

### **6. –û–±–Ω–æ–≤–∏—Ç–µ handlers.py:**
```bash
nano handlers.py
```

### **7. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É 7:**
```python
from config import AI_ENABLED
```

### **8. –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞:**
```python
from config import AI_ENABLED, VOICE_ENABLED
import speech_kit
```

### **9. –ù–∞–π–¥–∏—Ç–µ —Å—Ç—Ä–æ–∫—É —Å –æ–±—â–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–º (–ø—Ä–∏–º–µ—Ä–Ω–æ 1326):**
```python
# AI-—á–∞—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@router.message()
async def handle_ai_message(message: types.Message):
```

### **10. –î–æ–±–∞–≤—å—Ç–µ –ü–ï–†–ï–î —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π:**
```python
# AI-—á–∞—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@router.message(lambda message: message.voice is not None)
async def handle_voice_message(message: types.Message):
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è AI-—á–∞—Ç–∞ - –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ AI –∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        if not AI_ENABLED or not VOICE_ENABLED:
            return
            
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        username = message.from_user.username or message.from_user.first_name or "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å"
        chat_id = str(message.chat.id)
        
        logging.info(f"Processing voice message from {username}")
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        voice_file = await message.bot.get_file(message.voice.file_id)
        voice_data = await message.bot.download_file(voice_file.file_path)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç
        text_from_voice = speech_kit.voice_to_text(voice_data.read())
        
        if not text_from_voice:
            logging.warning("Failed to convert voice to text")
            return
            
        logging.info(f"Voice converted to text: {text_from_voice[:50]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ–ª–∂–µ–Ω –ª–∏ AI –æ—Ç–≤–µ—Ç–∏—Ç—å
        if yandex_ai.should_respond(text_from_voice, chat_id):
            logging.info(f"AI responding to voice message from {username}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            ai_response = yandex_ai.generate_response(text_from_voice, chat_id, username)
            
            if ai_response:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Ç–≤–µ—Ç –≤ –≥–æ–ª–æ—Å
                voice_response = speech_kit.text_to_voice(ai_response)
                
                if voice_response:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
                    await message.answer_voice(
                        voice=voice_response,
                        caption=f"üé§ {ai_response[:100]}{'...' if len(ai_response) > 100 else ''}"
                    )
                    logging.info(f"AI voice response sent: {ai_response[:50]}...")
                else:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥–æ–ª–æ—Å, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–º
                    await message.answer(f"üé§ {ai_response}")
                    logging.info(f"AI text response sent (voice failed): {ai_response[:50]}...")
            else:
                # Fallback –æ—Ç–≤–µ—Ç
                fallback_response = yandex_ai.get_random_comment()
                voice_fallback = speech_kit.text_to_voice(fallback_response)
                
                if voice_fallback:
                    await message.answer_voice(voice=voice_fallback)
                else:
                    await message.answer(fallback_response)
                    
    except Exception as e:
        logging.error(f"Error processing voice message: {e}")

```

### **11. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–æ—Ç–∞:**
```bash
docker-compose down
docker-compose up --build -d
```

## üé§ **–ì–æ—Ç–æ–≤–æ!**

–¢–µ–ø–µ—Ä—å –±–æ—Ç –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≥—Ä—É–±—ã–º –º—É–∂—Å–∫–∏–º –≥–æ–ª–æ—Å–æ–º! üó£Ô∏è‚ú®
